{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ydnrTrZosCMAp6cgeNGHbj7TlGVlcjGv",
      "authorship_tag": "ABX9TyOkFCjG4HZcRFiH6KQ5tCH8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mallesh06/Smart-Rain-Detection-Automated-Irrigation/blob/main/rain_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GovLF5D1eFoz"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch torchvision datasets pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor, ViTForImageClassification, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch"
      ],
      "metadata": {
        "id": "I2uBdeoXePun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/vit-base-patch16-224-in21k\"\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "model = ViTForImageClassification.from_pretrained(model_name, num_labels=3) # Changed num_labels to 3"
      ],
      "metadata": {
        "id": "ftnLhQOveksU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"imagefolder\", data_dir=\"/content/drive/MyDrive/Colab Notebooks/dataset\")\n",
        "\n",
        "# Verify\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "942YcKuwetwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])"
      ],
      "metadata": {
        "id": "i5GzE6E0e4_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./vit-finetuned-rain\",\n",
        "    per_device_train_batch_size=8,\n",
        "    eval_strategy=\"steps\",\n",
        "    num_train_epochs=3,  # You can increase to 5â€“10 if you have GPU time\n",
        "    save_steps=250,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-5,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",  # Disable Weights & Biases logging\n",
        ")"
      ],
      "metadata": {
        "id": "z_McEQUvfLyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ],
      "metadata": {
        "id": "KnNDjBTdfQzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(examples):\n",
        "    # Apply the defined transformations to the 'image' column\n",
        "    examples[\"pixel_values\"] = [train_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
        "    # Return only the processed pixel values and the labels\n",
        "    return {\"pixel_values\": examples[\"pixel_values\"], \"label\": examples[\"label\"]}\n",
        "\n",
        "# Apply the preprocessing function to the dataset\n",
        "processed_dataset = dataset.map(preprocess_image, batched=True)\n",
        "\n",
        "# Remove the original 'image' column as it's no longer needed\n",
        "processed_dataset = processed_dataset.remove_columns([\"image\"])\n",
        "\n",
        "# Verify the structure of the processed dataset\n",
        "print(processed_dataset)"
      ],
      "metadata": {
        "id": "hTNdYiUmfVkL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}